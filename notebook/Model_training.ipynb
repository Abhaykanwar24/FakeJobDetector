{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb042e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3d144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fake_job_posting_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e589ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "employment_encoded = ohe.fit_transform(df[['employment_type']])\n",
    "emp_df = pd.DataFrame(employment_encoded, columns=ohe.get_feature_names_out(['employment_type']))\n",
    "df = pd.concat([df.drop(['employment_type'], axis=1), emp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92569718",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_order = {\n",
    "    \"unknown\": 0,\n",
    "    \"internship\": 1,\n",
    "    \"entry level\": 2,\n",
    "    \"associate\": 3,\n",
    "    \"mid-senior level\": 4,\n",
    "    \"director\": 5,\n",
    "    \"executive\": 6,\n",
    "    \"not applicable\": 0\n",
    "}\n",
    "df['required_experience_encoded'] = df['required_experience'].map(experience_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ff9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_order = {\n",
    "    \"unknown\": 0,\n",
    "    \"some high school coursework\": 1,\n",
    "    \"high school or equivalent\": 2,\n",
    "    \"vocational - hs diploma\": 3,\n",
    "    \"vocational\": 4,\n",
    "    \"some college coursework completed\": 5,\n",
    "    \"associate degree\": 6,\n",
    "    \"bachelor's degree\": 7,\n",
    "    \"vocational - degree\": 8,\n",
    "    \"master's degree\": 9,\n",
    "    \"professional\": 10,\n",
    "    \"doctorate\": 11,\n",
    "    \"certification\": 12\n",
    "}\n",
    "\n",
    "df['required_education_encoded'] = df['required_education'].map(education_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67120d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([ 'required_experience', 'required_education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972f93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text']=df['full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedde3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     D:\\Data_Science\\NLP_for_ml\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d660fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \" \".join(text.split())\n",
    "    # Remove stopwords\n",
    "    text = \" \".join([w for w in text.split() if w.lower() not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['full_text'] = df['full_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a1134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f33c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e891d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac39f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text']=df['full_text'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d750ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['job_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76e2db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fraudulent', axis=1)\n",
    "y = df['fraudulent'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "425f982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,\n",
    "                                              test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae81d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf=tfidf.fit_transform(X_train['full_text']).toarray()\n",
    "X_test_tfidf=tfidf.transform(X_test['full_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56c2437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_cols = ['full_text'] \n",
    "\n",
    "X_train_other = X_train.drop(columns=text_cols).values\n",
    "X_test_other = X_test.drop(columns=text_cols).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03387fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.hstack([X_train_tfidf, X_train_other])\n",
    "X_test_final = np.hstack([X_test_tfidf, X_test_other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35b37d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ✅ Apply SMOTE only on training data\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982badd0",
   "metadata": {},
   "source": [
    "## Why is used SMOTE\n",
    "- If you miss fraud (low recall) → real people may get scammed → high risk, costly.\n",
    "\n",
    "- If you raise a few false alarms (lower precision) → a legitimate job gets flagged for manual review → inconvenience, but not deadly.\n",
    "\n",
    "- So in this domain, recall is more important than precision.\n",
    "It’s better to flag 100 jobs and catch 80 frauds (with some false positives) than flag only 70 frauds but miss 30 scammers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c460926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27214, 5010)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c6870ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraudulent\n",
       "0    13607\n",
       "1    13607\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f65e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2046369",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'LinearSVC': LinearSVC(max_iter=1000),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\fakejobdetector\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:20:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  Accuracy  F1-score  Precision    Recall\n",
      "5             XGBoost  0.987136  0.864706   0.930380  0.807692\n",
      "4           LinearSVC  0.983781  0.837989   0.852273  0.824176\n",
      "2        RandomForest  0.982662  0.797386   0.983871  0.670330\n",
      "1  LogisticRegression  0.973434  0.775414   0.680498  0.901099\n",
      "0          GaussianNB  0.964206  0.670103   0.631068  0.714286\n",
      "3            AdaBoost  0.938199  0.564103   0.440000  0.785714\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Save results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'F1-score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by='F1-score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51249be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb922bdf",
   "metadata": {},
   "source": [
    "## lets do hyperparameter tunning on Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfc0b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd283bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d40fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"max_depth\": [3, 5, 7, 9],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.3],\n",
    "    \"reg_lambda\": [1, 1.5, 2.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3caf1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,              # number of random combos to try\n",
    "    scoring=\"f1\",           # optimize for F1 because imbalanced dataset\n",
    "    cv=3,                   # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1520e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\fakejobdetector\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:42:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'subsample': 1.0, 'reg_lambda': 1.5, 'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "Best F1 Score: 0.9951022995422297\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy : 0.9874161073825504\n",
      "F1-score : 0.8664688427299704\n",
      "Precision: 0.9419354838709677\n",
      "Recall   : 0.8021978021978022\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 Score:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_xgb = random_search.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test_final)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af74ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\fakejobdetector\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:02:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "Accuracy : 0.9885346756152126\n",
      "F1-score : 0.8714733542319749\n",
      "Precision: 0.9266666666666666\n",
      "Recall   : 0.8224852071005917\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "xgb_best = xgb.XGBClassifier(\n",
    "    subsample=1.0,\n",
    "    reg_lambda=1.5,\n",
    "    n_estimators=400,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.05,\n",
    "    gamma=0.1,\n",
    "    colsample_bytree=0.6,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "xgb_best.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = xgb_best.predict(X_test_final)\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f10f31",
   "metadata": {},
   "source": [
    "## lets export the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81c8dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved as xgb_fakejob_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(xgb_best, \"xgb_fakejob_model.pkl\")\n",
    "print(\" Model saved as xgb_fakejob_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd9df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
